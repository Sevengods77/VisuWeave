{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='The heart is an important part of the human body.'), Document(metadata={}, page_content='The organ pumps blood through the blood vessels.'), Document(metadata={}, page_content='The pumped blood carries oxygen and nutrients to the tissue,'), Document(metadata={}, page_content='to the tissue, while carrying metabolic waste such as carbon'), Document(metadata={}, page_content='such as carbon dioxide to the lungs.'), Document(metadata={}, page_content='In humans, the heart is divided into four chambers: upper left'), Document(metadata={}, page_content='upper left and right atria and lower left and right ventricles.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text = \"\"\" The heart is an important part of the human body.\n",
    "The organ pumps blood through the blood vessels.\n",
    "The pumped blood carries oxygen and nutrients to the tissue, while carrying metabolic waste such as carbon dioxide to the lungs.\n",
    "In humans, the heart is divided into four chambers: upper left and right atria and lower left and right ventricles.\"\"\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=64, chunk_overlap=20)\n",
    "docs = text_splitter.create_documents([text])\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The heart is an important part of the human body.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=text_splitter.split_text(text)\n",
    "#print(len(chunks))\n",
    "#chunks[2]\n",
    "text_splitter.split_text(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "messages=Queue()\n",
    "recordings=Queue()\n",
    "channels=1\n",
    "frame_rate=16000\n",
    "record_seconds=20\n",
    "audio_format=pyaudio.paInt16\n",
    "sample_size=2\n",
    "\n",
    "def record_microphone(chunk=12045):\n",
    "    p=pyaudio.PyAudio()\n",
    "    stream=p.open(format=audio_format,\n",
    "                  channels=channels,\n",
    "                  rate=frame_rate,\n",
    "                  input=True,\n",
    "                  input_device_index=2,\n",
    "                  frames_per_buffer=chunk)\n",
    "    frames=[]\n",
    "    while not messages.empty():\n",
    "        data=stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        if len(frames)>=(frame_rate*record_seconds)/chunk:\n",
    "            recordings.put(frames.copy())\n",
    "            frames=[]\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vosk-model-en-us-0.22.zip:  13%|█▎        | 238M/1.78G [00:39<04:02, 6.87MB/s]    "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from vosk import Model,KaldiRecognizer\n",
    "model=Model(model_name=\"vosk-model-en-us-0.22\")\n",
    "rec=KaldiRecognizer(model,frame_rate)\n",
    "rec.SetWords(True)\n",
    "\n",
    "def speech_recognition(output):\n",
    "    while not messages.empty():\n",
    "        frames=recordings.get()\n",
    "        rec.AcceptWaveform(b''.join(frames))\n",
    "        result=rec.Result()\n",
    "        text=json.loads(result)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1877440006.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    transcribe=Thread(target=speech_recognition, args(output,))\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "\n",
    "record_button=widgets.Button(\n",
    "    description=\"Record\",\n",
    "    disabled=False,\n",
    "    button_style=\"success\",\n",
    "    icon=\"microphone\"\n",
    ")\n",
    "stop_button=widgets.Button(\n",
    "    description=\"Stop\",\n",
    "    disabled=False,\n",
    "    button_style=\"warning\",\n",
    "    icon=\"stop\"\n",
    ")\n",
    "def start_recording(data):\n",
    "    messages.put(True)\n",
    "    with output:\n",
    "        display(\"Starting....\")\n",
    "        record=Thread(target=record_microphone)\n",
    "        record.start()\n",
    "        transcribe=Thread(target=speech_recognition, args(output,))\n",
    "        transcribe.start()\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display(\"Stopped.\")\n",
    "\n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "output=widgets.Output()\n",
    "display(record_button,stop_button,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Chunks:\n",
      "Chunk 1: 'The quick brown fox jumps over the lazy dog. This is the first sentence.'\n",
      "Chunk 2: 'The lazy dog barks loudly at the fox. This is the second sentence, and it's quite important.'\n",
      "Chunk 3: 'Jumping foxes and barking dogs are common sights in the countryside.'\n",
      "Chunk 4: 'Countryside life is peaceful and quiet, unlike the busy city.'\n",
      "Chunk 5: 'The city never sleeps, with its constant noise and activity.'\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords per Chunk:\n",
      "Chunk 1: ['quick', 'brown', 'fox', 'jumps', 'lazy']\n",
      "Chunk 2: ['lazy', 'dog', 'barks', 'loudly', 'fox']\n",
      "Chunk 3: ['jumping', 'foxes', 'barking', 'dogs', 'common']\n",
      "Chunk 4: ['countryside', 'life', 'peaceful', 'quiet', 'unlike']\n",
      "Chunk 5: ['city', 'never', 'sleeps', 'constant', 'noise']\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract_keywords_from_chunks(chunks, keyword_extractor_model=\"bert-base-uncased\"):\n",
    "\n",
    "    keyword_extraction_pipeline = pipeline(\"feature-extraction\", model=keyword_extractor_model)\n",
    "    chunk_keywords = {}\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():  # Process only non-empty chunks\n",
    "            try:\n",
    "                embeddings = keyword_extraction_pipeline(chunk)\n",
    "                from collections import Counter\n",
    "                import nltk\n",
    "                from nltk.corpus import stopwords\n",
    "                from nltk.tokenize import word_tokenize\n",
    "\n",
    "                nltk.download('punkt', quiet=True)\n",
    "                nltk.download('stopwords', quiet=True)\n",
    "\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                word_tokens = word_tokenize(chunk.lower())\n",
    "                filtered_words = [w for w in word_tokens if not w in stop_words and w.isalnum()]\n",
    "                word_counts = Counter(filtered_words)\n",
    "                top_n = min(5, len(word_counts))  # Extract top 5 or fewer keywords\n",
    "                keywords = [word for word, count in word_counts.most_common(top_n)]\n",
    "\n",
    "                chunk_keywords[f\"Chunk {i+1}\"] = keywords\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {i+1}: {e}\")\n",
    "                chunk_keywords[f\"Chunk {i+1}\"] = []\n",
    "        else:\n",
    "            chunk_keywords[f\"Chunk {i+1}\"] = []\n",
    "\n",
    "    return chunk_keywords\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        # Sample chunkified data (replace with your actual chunks)\n",
    "    text = \"\"\"\n",
    "    The quick brown fox jumps over the lazy dog. This is the first sentence.\n",
    "    The lazy dog barks loudly at the fox. This is the second sentence, and it's quite important.\n",
    "    Jumping foxes and barking dogs are common sights in the countryside.\n",
    "    Countryside life is peaceful and quiet, unlike the busy city.\n",
    "    The city never sleeps, with its constant noise and activity.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "# Initialize recognizer\n",
    "    print(\"Generated Chunks:\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Extract keywords for each chunk\n",
    "    keywords_per_chunk = extract_keywords_from_chunks(chunks)\n",
    "\n",
    "    print(\"Keywords per Chunk:\")\n",
    "    for chunk_id, keywords in keywords_per_chunk.items():\n",
    "        print(f\"{chunk_id}: {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Chunks:\n",
      "Chunk 1: 'The majestic elephant roams the African savanna under the bright sun.\n",
      "    A playful golden retriever puppy chases a red ball in a green park.'\n",
      "Chunk 2: 'The snow-capped mountains stand tall against the clear blue sky.\n",
      "    A delicious pepperoni pizza sits on a wooden table with melted cheese.'\n",
      "Chunk 3: 'The old lighthouse warns ships of the rocky coastline during a storm.'\n",
      "------------------------------\n",
      "\n",
      "Chunk 1: 'The majestic elephant roams the African savanna un...'\n",
      "  Extracted Keywords: ['majestic', 'elephant', 'roams']\n",
      "  Generating image for: 'A realistic image of majestic'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of majestic': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of elephant'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of elephant': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of roams'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of roams': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "\n",
      "Chunk 2: 'The snow-capped mountains stand tall against the c...'\n",
      "  Extracted Keywords: ['mountains', 'stand', 'tall']\n",
      "  Generating image for: 'A realistic image of mountains'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of mountains': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of stand'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of stand': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of tall'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of tall': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "\n",
      "Chunk 3: 'The old lighthouse warns ships of the rocky coastl...'\n",
      "  Extracted Keywords: ['old', 'lighthouse', 'warns']\n",
      "  Generating image for: 'A realistic image of old'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of old': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of lighthouse'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of lighthouse': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "  Generating image for: 'A realistic image of warns'...\n",
      "Error generating image (Hugging Face) for 'A realistic image of warns': 404 Client Error: Not Found for url: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\n",
      "\n",
      "Image generation process completed.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Download necessary NLTK data (run once)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "HUGGINGFACE_API_TOKEN = \"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\"  # Replace with your actual API token\n",
    "API_URL = \"https://huggingface.co/stabilityai/stable-diffusion-3.5-large\" # You can try other Stable Diffusion models\n",
    "OUTPUT_DIR = \"generated_images\"\n",
    "\n",
    "def extract_keywords(text, num_keywords=3):\n",
    "    \"\"\"Extracts top N keywords from text using a simple frequency-based method.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_words = [w for w in word_tokens if w.isalnum() and w not in stop_words]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return [word for word, count in word_counts.most_common(num_keywords)]\n",
    "\n",
    "def generate_image_huggingface(prompt, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"Generates an image using the Hugging Face Inference API.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"}\n",
    "    payload = {\"inputs\": prompt}\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        image_bytes = response.content\n",
    "        image = Image.open(BytesIO(image_bytes))\n",
    "        filename = f\"{prompt.replace(' ', '_')[:50]}_hf.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        image.save(filepath)\n",
    "        print(f\"Generated image for '{prompt}' (Hugging Face) and saved to '{filepath}'\")\n",
    "        return filepath\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating image (Hugging Face) for '{prompt}': {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_images_for_chunks(chunks, output_dir=\"generated_images\"):\n",
    "    \"\"\"\n",
    "    Extracts keywords from each chunk and generates an image for each keyword\n",
    "    using the Hugging Face Inference API.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): A list of strings, where each string is a chunk of text.\n",
    "        output_dir (str): The directory to save the generated images.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_keywords(chunk)\n",
    "            print(f\"\\nChunk {i+1}: '{chunk[:50]}...'\")\n",
    "            print(f\"  Extracted Keywords: {keywords}\")\n",
    "            for keyword in keywords:\n",
    "                prompt = f\"A realistic image of {keyword}\"  # You can adjust the prompt\n",
    "                print(f\"  Generating image for: '{prompt}'...\")\n",
    "                generate_image_huggingface(prompt, output_dir)\n",
    "        else:\n",
    "            print(f\"\\nChunk {i+1}: Empty chunk, skipping image generation.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample chunkified data (replace with your actual chunks)\n",
    "    text = \"\"\"\n",
    "    The majestic elephant roams the African savanna under the bright sun.\n",
    "    A playful golden retriever puppy chases a red ball in a green park.\n",
    "    The snow-capped mountains stand tall against the clear blue sky.\n",
    "    A delicious pepperoni pizza sits on a wooden table with melted cheese.\n",
    "    The old lighthouse warns ships of the rocky coastline during a storm.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    print(\"Generated Chunks:\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Generate images for keywords in each chunk\n",
    "    generate_images_for_chunks(chunks)\n",
    "    print(\"\\nImage generation process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Chunks:\n",
      "Chunk 1: 'The majestic elephant roams the African savanna under the bright sun.\n",
      "    A playful golden retriever puppy chases a red ball in a green park.'\n",
      "Chunk 2: 'The snow-capped mountains stand tall against the clear blue sky.\n",
      "    A delicious pepperoni pizza sits on a wooden table with melted cheese.'\n",
      "Chunk 3: 'The old lighthouse warns ships of the rocky coastline during a storm.'\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/sevengods/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:06<00:00, 15.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1: 'The majestic elephant roams the African savanna un...' ---\n",
      "  Extracted Keywords: ['majestic', 'elephant', 'roams']\n",
      "  Generating image for: 'A realistic image of majestic'...\n",
      "Error generating image for 'A realistic image of majestic': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f559700>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of elephant'...\n",
      "Error generating image for 'A realistic image of elephant': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f55af60>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of roams'...\n",
      "Error generating image for 'A realistic image of roams': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f54fc80>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "\n",
      "--- Chunk 2: 'The snow-capped mountains stand tall against the c...' ---\n",
      "  Extracted Keywords: ['mountains', 'stand', 'tall']\n",
      "  Generating image for: 'A realistic image of mountains'...\n",
      "Error generating image for 'A realistic image of mountains': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f546d50>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of stand'...\n",
      "Error generating image for 'A realistic image of stand': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f544cb0>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of tall'...\n",
      "Error generating image for 'A realistic image of tall': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f54f410>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "\n",
      "--- Chunk 3: 'The old lighthouse warns ships of the rocky coastl...' ---\n",
      "  Extracted Keywords: ['old', 'lighthouse', 'warns']\n",
      "  Generating image for: 'A realistic image of old'...\n",
      "Error generating image for 'A realistic image of old': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f5447d0>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of lighthouse'...\n",
      "Error generating image for 'A realistic image of lighthouse': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f544380>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "  Generating image for: 'A realistic image of warns'...\n",
      "Error generating image for 'A realistic image of warns': HTTPSConnectionPool(host='api.replit.com', port=443): Max retries exceeded with url: /v1/ai/image (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x70414f559b80>: Failed to resolve 'api.replit.com' ([Errno -2] Name or service not known)\"))\n",
      "\n",
      "--- Evaluating and Refining Temporal Chunks ---\n",
      "\n",
      "--- Analyzing Fused Visual Sequence ---\n",
      "Coherence of Fused Sequence: 1.0\n",
      "Similarity of Fused Sequence: 1.0\n",
      "\n",
      "Final Fused Visual Sequence Image Paths:\n",
      "[]\n",
      "\n",
      "Image generation, evaluation, and fusion process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Download necessary NLTK data (run once)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "CHUNK_SIZE_T = 5  # Example: Group images into chunks of 5 (adjust as needed)\n",
    "SSIM_THRESHOLD_TC = 0.75  # Threshold for acceptable coherence (adjust as needed)\n",
    "OUTPUT_DIR = \"generated_images\"\n",
    "FEATURE_EXTRACTION_LAYER = 'layer4'  # Layer to extract features from ResNet\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def extract_keywords(text, num_keywords=3):\n",
    "    \"\"\"Extracts top N keywords from text using a simple frequency-based method.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_words = [w for w in word_tokens if w.isalnum() and w not in stop_words]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return [word for word, count in word_counts.most_common(num_keywords)]\n",
    "\n",
    "def generate_image_craiyon(prompt, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"Generates an image using the Craiyon API (via Replit's free wrapper).\"\"\"\n",
    "    api_url = \"https://api.replit.com/v1/ai/image\"\n",
    "    payload = {\"prompt\": prompt}\n",
    "    try:\n",
    "        response = requests.post(api_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data and 'imageUrls' in data and data['imageUrls']:\n",
    "            image_url = data['imageUrls'][0]\n",
    "            image_response = requests.get(image_url)\n",
    "            image_response.raise_for_status()\n",
    "            image = Image.open(BytesIO(image_response.content)).convert('RGB')\n",
    "            filename = f\"{prompt.replace(' ', '_')[:50]}.png\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            image.save(filepath)\n",
    "            print(f\"Generated image for '{prompt}' and saved to '{filepath}'\")\n",
    "            return filepath, image\n",
    "        else:\n",
    "            print(f\"Error: Could not retrieve image URL for prompt: {prompt}\")\n",
    "            return None, None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating image for '{prompt}': {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_image_array(image):\n",
    "    \"\"\"Converts a PIL Image to a NumPy array.\"\"\"\n",
    "    return np.array(image)\n",
    "\n",
    "def calculate_ssim(image1, image2):\n",
    "    \"\"\"Calculates the Structural Similarity Index (SSIM) between two images.\"\"\"\n",
    "    if image1 is None or image2 is None:\n",
    "        return 0.0\n",
    "    img1_gray = image1.convert('L')\n",
    "    img2_gray = image2.convert('L')\n",
    "    array1 = get_image_array(img1_gray)\n",
    "    array2 = get_image_array(img2_gray)\n",
    "    return ssim(array1, array2, data_range=array2.max() - array2.min())\n",
    "\n",
    "def get_image_features(image, model, layer_name, transform):\n",
    "    \"\"\"Extracts features from a specific layer of a pre-trained ResNet model.\"\"\"\n",
    "    if image is None:\n",
    "        return None\n",
    "    image_t = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    features = None\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output.flatten(start_dim=1).detach().cpu().numpy()\n",
    "\n",
    "    layer = getattr(model, layer_name)\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    model(image_t)\n",
    "    handle.remove()\n",
    "    return features\n",
    "\n",
    "def calculate_cosine_similarity(features1, features2):\n",
    "    \"\"\"Calculates the cosine similarity between two feature vectors.\"\"\"\n",
    "    if features1 is None or features2 is None:\n",
    "        return 0.0\n",
    "    features1_tensor = torch.tensor(features1).float()\n",
    "    features2_tensor = torch.tensor(features2).float()\n",
    "    return cosine_similarity(features1_tensor, features2_tensor).item()\n",
    "\n",
    "def assess_chunk_coherence(image_paths):\n",
    "    \"\"\"Calculates the coherence score for a chunk of images based on SSIM.\"\"\"\n",
    "    if len(image_paths) < 2:\n",
    "        return 1.0  # Consider a single image chunk as coherent\n",
    "\n",
    "    ssim_scores = []\n",
    "    images = [Image.open(path).convert('RGB') for path in image_paths]\n",
    "\n",
    "    for i in range(len(images) - 1):\n",
    "        score = calculate_ssim(images[i], images[i+1])\n",
    "        ssim_scores.append(score)\n",
    "\n",
    "    coherence = sum(1 for score in ssim_scores if score > SSIM_THRESHOLD_TC) / (len(ssim_scores) if ssim_scores else 1)\n",
    "    return coherence\n",
    "\n",
    "def assess_chunk_similarity(image_paths, model, transform):\n",
    "    \"\"\"Calculates the average cosine similarity of features between adjacent images in a chunk.\"\"\"\n",
    "    if len(image_paths) < 2:\n",
    "        return 1.0\n",
    "\n",
    "    similarities = []\n",
    "    images = [Image.open(path).convert('RGB') for path in image_paths]\n",
    "    features_list = [get_image_features(img, model, FEATURE_EXTRACTION_LAYER, transform) for img in images]\n",
    "\n",
    "    for i in range(len(features_list) - 1):\n",
    "        sim = calculate_cosine_similarity(features_list[i], features_list[i+1])\n",
    "        similarities.append(sim)\n",
    "\n",
    "    return np.mean(similarities) if similarities else 1.0\n",
    "\n",
    "def refine_chunk(image_paths, target_coherence, target_similarity, model, transform):\n",
    "    \"\"\"\n",
    "    Placeholder for a more sophisticated refinement procedure.\n",
    "    In a real system, this would involve techniques to improve coherence and similarity\n",
    "    if they fall below the target thresholds. This could include:\n",
    "    - Generating new images with slightly modified prompts.\n",
    "    - Selecting a subset of the existing images.\n",
    "    - Applying image processing techniques.\n",
    "    For this example, it simply prints a message.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Refining Chunk ---\")\n",
    "    print(f\"Current images in chunk: {image_paths}\")\n",
    "    print(f\"Target Coherence: {target_coherence}, Current Coherence: {assess_chunk_coherence(image_paths)}\")\n",
    "    print(f\"Target Similarity: {target_similarity}, Current Similarity: {assess_chunk_similarity(image_paths, model, transform)}\")\n",
    "    print(\"Refinement procedure not fully implemented in this example.\")\n",
    "    return image_paths # In a real system, this would return the refined set of image paths\n",
    "\n",
    "def fuse_and_compress_chunks(chunked_image_paths, model, transform, target_coherence=SSIM_THRESHOLD_TC, target_similarity=0.8):\n",
    "    \"\"\"\n",
    "    Fuses processed chunks into a single visual sequence and performs further analysis.\n",
    "    This is a simplified implementation.\n",
    "    \"\"\"\n",
    "    all_image_paths = [path for chunk in chunked_image_paths for path in chunk]\n",
    "\n",
    "    print(\"\\n--- Analyzing Fused Visual Sequence ---\")\n",
    "    coherence_fused = assess_chunk_coherence(all_image_paths)\n",
    "    similarity_fused = assess_chunk_similarity(all_image_paths, model, transform)\n",
    "    print(f\"Coherence of Fused Sequence: {coherence_fused}\")\n",
    "    print(f\"Similarity of Fused Sequence: {similarity_fused}\")\n",
    "\n",
    "    # Refinement of the combined sequence (placeholder)\n",
    "    if coherence_fused < target_coherence or similarity_fused < target_similarity:\n",
    "        print(\"Fused sequence requires refinement (refinement not fully implemented).\")\n",
    "\n",
    "    return all_image_paths\n",
    "\n",
    "def process_chunks(chunks, chunk_size_t=CHUNK_SIZE_T, ssim_threshold_tc=SSIM_THRESHOLD_TC):\n",
    "    \"\"\"Processes each chunk: extracts keywords, generates images, and evaluates coherence.\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    chunked_images = []\n",
    "    all_generated_image_paths = []\n",
    "\n",
    "    # Load pre-trained ResNet model for feature extraction\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights).to(DEVICE).eval()\n",
    "    transform = weights.transforms()\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_keywords(chunk)\n",
    "            print(f\"\\n--- Chunk {i+1}: '{chunk[:50]}...' ---\")\n",
    "            print(f\"  Extracted Keywords: {keywords}\")\n",
    "            image_paths_for_chunk = []\n",
    "            for keyword in keywords:\n",
    "                prompt = f\"A realistic image of {keyword}\"\n",
    "                print(f\"  Generating image for: '{prompt}'...\")\n",
    "                filepath, image = generate_image_craiyon(prompt, OUTPUT_DIR)\n",
    "                if filepath:\n",
    "                    image_paths_for_chunk.append(filepath)\n",
    "                    all_generated_image_paths.append(filepath)\n",
    "            chunked_images.append(image_paths_for_chunk)\n",
    "        else:\n",
    "            print(f\"\\n--- Chunk {i+1}: Empty chunk, skipping. ---\")\n",
    "            chunked_images.append([])\n",
    "\n",
    "    # Divide images into temporal chunks\n",
    "    temporal_image_chunks = [all_generated_image_paths[i:i + chunk_size_t]\n",
    "                              for i in range(0, len(all_generated_image_paths), chunk_size_t)]\n",
    "\n",
    "    print(\"\\n--- Evaluating and Refining Temporal Chunks ---\")\n",
    "    refined_temporal_chunks = []\n",
    "    for k, image_paths in enumerate(temporal_image_chunks):\n",
    "        print(f\"\\n-- Temporal Chunk {k+1} --\")\n",
    "        if not image_paths:\n",
    "            refined_temporal_chunks.append([])\n",
    "            continue\n",
    "\n",
    "        coherence = assess_chunk_coherence(image_paths)\n",
    "        similarity = assess_chunk_similarity(image_paths, model, transform)\n",
    "        print(f\"Initial Coherence: {coherence:.4f}\")\n",
    "        print(f\"Initial Similarity: {similarity:.4f}\")\n",
    "\n",
    "        if coherence < ssim_threshold_tc or similarity < 0.7: # Example similarity threshold\n",
    "            refined_chunk_paths = refine_chunk(image_paths, ssim_threshold_tc, 0.7, model, transform)\n",
    "            refined_temporal_chunks.append(refined_chunk_paths)\n",
    "        else:\n",
    "            refined_temporal_chunks.append(image_paths)\n",
    "\n",
    "    # Fuse and analyze the combined sequence\n",
    "    fused_sequence_paths = fuse_and_compress_chunks(refined_temporal_chunks, model, transform)\n",
    "    print(f\"\\nFinal Fused Visual Sequence Image Paths:\\n{fused_sequence_paths}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample chunkified data (replace with your actual chunks)\n",
    "    text = \"\"\"\n",
    "    The majestic elephant roams the African savanna under the bright sun.\n",
    "    A playful golden retriever puppy chases a red ball in a green park.\n",
    "    The snow-capped mountains stand tall against the clear blue sky.\n",
    "    A delicious pepperoni pizza sits on a wooden table with melted cheese.\n",
    "    The old lighthouse warns ships of the rocky coastline during a storm.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    print(\"Generated Chunks:\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1}: '{chunk}'\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Process the chunks to generate images and evaluate coherence\n",
    "    process_chunks(chunks)\n",
    "    print(\"\\nImage generation, evaluation, and fusion process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk 1: 'The majestic elephant roams the African savanna un...'\n",
      "  Extracted Nouns: ['elephant', 'savanna', 'sun']\n",
      "\n",
      "Chunk 2: 'The snow-capped mountains stand tall against the c...'\n",
      "  Extracted Nouns: ['mountains', 'tall', 'blue']\n",
      "\n",
      "Chunk 3: 'The old lighthouse warns ships of the rocky coastl...'\n",
      "  Extracted Nouns: ['lighthouse', 'ships', 'coastline']\n",
      "\n",
      "Starting image search for keywords: ['elephant', 'savanna', 'sun', 'mountains', 'tall', 'blue', 'lighthouse', 'ships', 'coastline']\n",
      "\n",
      "Searching images for: elephant\n",
      "Error searching images for elephant: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=elephant&searchType=image&num=3\n",
      "No images found for 'elephant'\n",
      "\n",
      "Searching images for: savanna\n",
      "Error searching images for savanna: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=savanna&searchType=image&num=3\n",
      "No images found for 'savanna'\n",
      "\n",
      "Searching images for: sun\n",
      "Error searching images for sun: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=sun&searchType=image&num=3\n",
      "No images found for 'sun'\n",
      "\n",
      "Searching images for: mountains\n",
      "Error searching images for mountains: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=mountains&searchType=image&num=3\n",
      "No images found for 'mountains'\n",
      "\n",
      "Searching images for: tall\n",
      "Error searching images for tall: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=tall&searchType=image&num=3\n",
      "No images found for 'tall'\n",
      "\n",
      "Searching images for: blue\n",
      "Error searching images for blue: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=blue&searchType=image&num=3\n",
      "No images found for 'blue'\n",
      "\n",
      "Searching images for: lighthouse\n",
      "Error searching images for lighthouse: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=lighthouse&searchType=image&num=3\n",
      "No images found for 'lighthouse'\n",
      "\n",
      "Searching images for: ships\n",
      "Error searching images for ships: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=ships&searchType=image&num=3\n",
      "No images found for 'ships'\n",
      "\n",
      "Searching images for: coastline\n",
      "Error searching images for coastline: 400 Client Error: Bad Request for url: https://www.googleapis.com/customsearch/v1?key=YOUR_GOOGLE_API_KEY&cx=YOUR_SEARCH_ENGINE_ID&q=coastline&searchType=image&num=3\n",
      "No images found for 'coastline'\n",
      "\n",
      "Image extraction process completed.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "SEARCH_API_KEY = \"YOUR_GOOGLE_API_KEY\"  # Replace with your Google Custom Search API key\n",
    "SEARCH_ENGINE_ID = \"YOUR_SEARCH_ENGINE_ID\"  # Replace with your Custom Search Engine ID\n",
    "\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    \"\"\"Extracts top N noun keywords using POS tagging\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    # Filter nouns (NN, NNS, NNP, NNPS)\n",
    "    nouns = [word for (word, tag) in pos_tags \n",
    "            if tag in ['NN', 'NNS', 'NNP', 'NNPS'] \n",
    "            and word.isalnum() \n",
    "            and word not in stop_words]\n",
    "    \n",
    "    return [word for word, count in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "def search_images(keyword, num_images=3):\n",
    "    \"\"\"Searches for images using Google Custom Search API\"\"\"\n",
    "    try:\n",
    "        url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "        params = {\n",
    "            'key': SEARCH_API_KEY,\n",
    "            'cx': SEARCH_ENGINE_ID,\n",
    "            'q': keyword,\n",
    "            'searchType': 'image',\n",
    "            'num': num_images\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        \n",
    "        return [item['link'] for item in results.get('items', [])]\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching images for {keyword}: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_and_save_image(url, keyword, output_dir):\n",
    "    \"\"\"Downloads and saves an image from a URL\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Verify image content\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image.verify()  # Check if the file is a valid image\n",
    "        \n",
    "        # Convert to RGB if necessary and save\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        filename = f\"{keyword}_{os.urandom(4).hex()}.jpg\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        image.save(filepath, \"JPEG\")\n",
    "        print(f\"Saved image: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_chunks(chunks, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Processes text chunks to extract nouns and download related images\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_keywords = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_nouns(chunk)\n",
    "            print(f\"\\nChunk {i+1}: '{chunk[:50]}...'\")\n",
    "            print(f\"  Extracted Nouns: {keywords}\")\n",
    "            all_keywords.extend(keywords)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_keywords = [k for k in all_keywords if not (k in seen or seen.add(k))]\n",
    "    \n",
    "    print(\"\\nStarting image search for keywords:\", unique_keywords)\n",
    "    \n",
    "    for keyword in unique_keywords:\n",
    "        print(f\"\\nSearching images for: {keyword}\")\n",
    "        image_urls = search_images(keyword)\n",
    "        \n",
    "        if not image_urls:\n",
    "            print(f\"No images found for '{keyword}'\")\n",
    "            continue\n",
    "            \n",
    "        for url in image_urls:\n",
    "            download_and_save_image(url, keyword, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample text\n",
    "    text = \"\"\"\n",
    "    The majestic elephant roams the African savanna under the bright sun.\n",
    "    A playful golden retriever puppy chases a red ball in a green park.\n",
    "    The snow-capped mountains stand tall against the clear blue sky.\n",
    "    A delicious pepperoni pizza sits on a wooden table with melted cheese.\n",
    "    The old lighthouse warns ships of the rocky coastline during a storm.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Process chunks and download images\n",
    "    process_chunks(chunks)\n",
    "    print(\"\\nImage extraction process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk 1: 'The majestic elephant roams the African savanna un...'\n",
      "  Extracted Nouns: ['elephant', 'savanna', 'sun']\n",
      "\n",
      "Chunk 2: 'The snow-capped mountains stand tall against the c...'\n",
      "  Extracted Nouns: ['mountains', 'tall', 'blue']\n",
      "\n",
      "Chunk 3: 'The old lighthouse warns ships of the rocky coastl...'\n",
      "  Extracted Nouns: ['lighthouse', 'ships', 'coastline']\n",
      "\n",
      "Starting image search for keywords: ['elephant', 'savanna', 'sun', 'mountains', 'tall', 'blue', 'lighthouse', 'ships', 'coastline']\n",
      "\n",
      "Searching images for: elephant\n",
      "Chrome WebDriver failed: Message: unknown error: cannot kill Chrome\n",
      "from unknown error: DevToolsActivePort file doesn't exist\n",
      "Stacktrace:\n",
      "#0 0x5b1cafcfe4e3 <unknown>\n",
      "#1 0x5b1cafa2dc76 <unknown>\n",
      "#2 0x5b1cafa5a019 <unknown>\n",
      "#3 0x5b1cafa562fa <unknown>\n",
      "#4 0x5b1cafa53029 <unknown>\n",
      "#5 0x5b1cafa91ccc <unknown>\n",
      "#6 0x5b1cafa9147f <unknown>\n",
      "#7 0x5b1cafa88de3 <unknown>\n",
      "#8 0x5b1cafa5e2dd <unknown>\n",
      "#9 0x5b1cafa5f34e <unknown>\n",
      "#10 0x5b1cafcbe3e4 <unknown>\n",
      "#11 0x5b1cafcc23d7 <unknown>\n",
      "#12 0x5b1cafcccb20 <unknown>\n",
      "#13 0x5b1cafcc3023 <unknown>\n",
      "#14 0x5b1cafc911aa <unknown>\n",
      "#15 0x5b1cafce76b8 <unknown>\n",
      "#16 0x5b1cafce7847 <unknown>\n",
      "#17 0x5b1cafcf7243 <unknown>\n",
      "#18 0x771d6089caa4 <unknown>\n",
      "#19 0x771d60929c3c <unknown>\n",
      "\n",
      "Firefox WebDriver failed: HTTPConnectionPool(host='localhost', port=39647): Read timed out. (read timeout=120)\n",
      "No WebDriver available. Exiting.\n",
      "No images found for 'elephant'\n",
      "\n",
      "Searching images for: savanna\n",
      "Chrome WebDriver failed: Message: unknown error: cannot kill Chrome\n",
      "from unknown error: DevToolsActivePort file doesn't exist\n",
      "Stacktrace:\n",
      "#0 0x6545f99c54e3 <unknown>\n",
      "#1 0x6545f96f4c76 <unknown>\n",
      "#2 0x6545f9721019 <unknown>\n",
      "#3 0x6545f971d2fa <unknown>\n",
      "#4 0x6545f971a029 <unknown>\n",
      "#5 0x6545f9758ccc <unknown>\n",
      "#6 0x6545f975847f <unknown>\n",
      "#7 0x6545f974fde3 <unknown>\n",
      "#8 0x6545f97252dd <unknown>\n",
      "#9 0x6545f972634e <unknown>\n",
      "#10 0x6545f99853e4 <unknown>\n",
      "#11 0x6545f99893d7 <unknown>\n",
      "#12 0x6545f9993b20 <unknown>\n",
      "#13 0x6545f998a023 <unknown>\n",
      "#14 0x6545f99581aa <unknown>\n",
      "#15 0x6545f99ae6b8 <unknown>\n",
      "#16 0x6545f99ae847 <unknown>\n",
      "#17 0x6545f99be243 <unknown>\n",
      "#18 0x7f467f09caa4 <unknown>\n",
      "#19 0x7f467f129c3c <unknown>\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 152\u001b[0m\n\u001b[1;32m    149\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(text)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Process chunks and download images\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m process_chunks(chunks)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mImage extraction process completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 128\u001b[0m, in \u001b[0;36mprocess_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m unique_keywords:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSearching images for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m     image_urls \u001b[38;5;241m=\u001b[39m fetch_google_images(keyword)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_urls:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 73\u001b[0m, in \u001b[0;36mfetch_google_images\u001b[0;34m(query, num_images)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_google_images\u001b[39m(query, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scrapes image URLs from Google Images using Selenium with timeout.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     driver \u001b[38;5;241m=\u001b[39m init_browser()\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m driver:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m, in \u001b[0;36minit_browser\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m     service \u001b[38;5;241m=\u001b[39m FirefoxService(GeckoDriverManager()\u001b[38;5;241m.\u001b[39minstall())\n\u001b[0;32m---> 58\u001b[0m     driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mFirefox(service\u001b[38;5;241m=\u001b[39mservice, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m     60\u001b[0m driver\u001b[38;5;241m.\u001b[39mset_page_load_timeout(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Set timeout for page load\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;241m.\u001b[39mcapitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m WebDriver\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/firefox/webdriver.py:71\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     64\u001b[0m executor \u001b[38;5;241m=\u001b[39m FirefoxRemoteConnection(\n\u001b[1;32m     65\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     66\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     67\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(command_executor\u001b[38;5;241m=\u001b[39mexecutor, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:250\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_session(capabilities)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fedcm \u001b[38;5;241m=\u001b[39m FedCM(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_websocket_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    - A capabilities dict to start the session with.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[0;32m--> 342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mNEW_SESSION, caps)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    425\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[1;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    136\u001b[0m         method,\n\u001b[1;32m    137\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m    145\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlpro/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"extracted_images\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_nouns(text, num_keywords=3):\n",
    "    \"\"\"Extracts top N noun keywords using POS tagging\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    # Filter nouns (NN, NNS, NNP, NNPS)\n",
    "    nouns = [word for (word, tag) in pos_tags \n",
    "             if tag in ['NN', 'NNS', 'NNP', 'NNPS'] \n",
    "             and word.isalnum() \n",
    "             and word not in stop_words]\n",
    "    \n",
    "    return [word for word, count in Counter(nouns).most_common(num_keywords)]\n",
    "\n",
    "def init_browser():\n",
    "    \"\"\"Tries to initialize Chrome first, then Firefox if Chrome fails.\"\"\"\n",
    "    for browser in [\"chrome\", \"firefox\"]:\n",
    "        try:\n",
    "            options = None\n",
    "            service = None\n",
    "            if browser == \"chrome\":\n",
    "                options = webdriver.ChromeOptions()\n",
    "                options.add_argument(\"--headless\")\n",
    "                options.add_argument(\"--no-sandbox\")\n",
    "                options.add_argument(\"--disable-dev-shm-usage\")\n",
    "                service = ChromeService(ChromeDriverManager().install())\n",
    "                driver = webdriver.Chrome(service=service, options=options)\n",
    "            else:\n",
    "                options = webdriver.FirefoxOptions()\n",
    "                options.add_argument(\"--headless\")\n",
    "                service = FirefoxService(GeckoDriverManager().install())\n",
    "                driver = webdriver.Firefox(service=service, options=options)\n",
    "            \n",
    "            driver.set_page_load_timeout(5)  # Set timeout for page load\n",
    "            print(f\"Using {browser.capitalize()} WebDriver\")\n",
    "            return driver\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{browser.capitalize()} WebDriver failed: {e}\")\n",
    "            continue  # Try next browser\n",
    "    \n",
    "    print(\"No WebDriver available. Exiting.\")\n",
    "    return None\n",
    "\n",
    "def fetch_google_images(query, num_images=3):\n",
    "    \"\"\"Scrapes image URLs from Google Images using Selenium with timeout.\"\"\"\n",
    "    driver = init_browser()\n",
    "    if not driver:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        search_url = f\"https://www.google.com/search?tbm=isch&q={query}\"\n",
    "        driver.get(search_url)\n",
    "        time.sleep(2)  # Allow time to load\n",
    "\n",
    "        images = []\n",
    "        img_elements = driver.find_elements(By.CSS_SELECTOR, \"img.Q4LuWd\")\n",
    "\n",
    "        for img in img_elements:\n",
    "            img_url = img.get_attribute(\"src\")\n",
    "            if img_url:\n",
    "                images.append(img_url)\n",
    "            if len(images) >= num_images:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching images: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return images\n",
    "\n",
    "def download_and_save_image(url, keyword, output_dir):\n",
    "    \"\"\"Downloads and saves an image from a URL with a timeout.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # Set timeout for requests\n",
    "        response.raise_for_status()\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        filename = f\"{keyword}_{os.urandom(4).hex()}.jpg\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        image.save(filepath, \"JPEG\")\n",
    "        print(f\"Saved image: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "def process_chunks(chunks):\n",
    "    \"\"\"Processes text chunks to extract nouns and download images.\"\"\"\n",
    "    all_keywords = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if chunk.strip():\n",
    "            keywords = extract_nouns(chunk)\n",
    "            print(f\"\\nChunk {i+1}: '{chunk[:50]}...'\")\n",
    "            print(f\"  Extracted Nouns: {keywords}\")\n",
    "            all_keywords.extend(keywords)\n",
    "    \n",
    "    unique_keywords = list(dict.fromkeys(all_keywords))  # Remove duplicates while preserving order\n",
    "    \n",
    "    print(\"\\nStarting image search for keywords:\", unique_keywords)\n",
    "    for keyword in unique_keywords:\n",
    "        print(f\"\\nSearching images for: {keyword}\")\n",
    "        image_urls = fetch_google_images(keyword)\n",
    "        \n",
    "        if not image_urls:\n",
    "            print(f\"No images found for '{keyword}'\")\n",
    "            continue\n",
    "        \n",
    "        for url in image_urls:\n",
    "            download_and_save_image(url, keyword, OUTPUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample text\n",
    "    text = \"\"\"\n",
    "    The majestic elephant roams the African savanna under the bright sun.\n",
    "    A playful golden retriever puppy chases a red ball in a green park.\n",
    "    The snow-capped mountains stand tall against the clear blue sky.\n",
    "    A delicious pepperoni pizza sits on a wooden table with melted cheese.\n",
    "    The old lighthouse warns ships of the rocky coastline during a storm.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Process chunks and download images\n",
    "    process_chunks(chunks)\n",
    "    print(\"\\nImage extraction process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for 'dhoni' saved to 'downloaded_images/dhoni.jpg'\n",
      "Image successfully scraped and saved to: downloaded_images/dhoni.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def scrape_image_from_web(keyword, output_dir=\"downloaded_images\"):\n",
    "    \"\"\"\n",
    "    Scrapes the first image from a Google Images search for a given keyword\n",
    "    and saves it to the specified output directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    search_url = f\"https://www.google.com/search?q={keyword}&tbm=isch\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "\n",
    "        if not img_tags:\n",
    "            print(\"No images found on the page.\")\n",
    "            return None\n",
    "\n",
    "        # The first image tag often contains the actual image\n",
    "        img_url = img_tags[1].get('src')  # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "        if not img_url or img_url.startswith('data:image'):\n",
    "            img_url = img_tags[1].get('data-src') # Try the second image tag first (index 1), it has a higher chance of being the full image url\n",
    "\n",
    "        if not img_url:\n",
    "          print(\"Could not find the image URL.\")\n",
    "          return None\n",
    "\n",
    "\n",
    "        # Download the image\n",
    "        try:\n",
    "            img_response = requests.get(img_url, stream=True, timeout=10)\n",
    "            img_response.raise_for_status()\n",
    "            image = Image.open(BytesIO(img_response.content))\n",
    "\n",
    "            # Save the image\n",
    "            filename = f\"{keyword.replace(' ', '_')}.jpg\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            image.save(filepath, \"JPEG\")\n",
    "\n",
    "            print(f\"Image for '{keyword}' saved to '{filepath}'\")\n",
    "            return filepath\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading the image: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "          print(f\"Error processing the image {e}\")\n",
    "          return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during the search request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "      print(f\"Other error occurred: {e}\")\n",
    "      return None\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = \"mia khalifa\"  # Replace with your desired keyword\n",
    "    image_path = scrape_image_from_web(keyword)\n",
    "\n",
    "    if image_path:\n",
    "        print(f\"Image successfully scraped and saved to: {image_path}\")\n",
    "    else:\n",
    "        print(\"Failed to scrape and save the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
